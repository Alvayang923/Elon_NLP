{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b4b9fe",
   "metadata": {},
   "source": [
    "# Elon Musk Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a14979",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d647e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8890cb",
   "metadata": {},
   "source": [
    "## 1. Get the data from the /data repository, combine in one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22222aec",
   "metadata": {},
   "source": [
    "#### Define path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36d955bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/'\n",
    "the_data_out = r'../outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f8f76",
   "metadata": {},
   "source": [
    "#### Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7faf432",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13079929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>time</th>\n",
       "      <th>mentions</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>15434727182</td>\n",
       "      <td>15434727182</td>\n",
       "      <td>1275676317000.0</td>\n",
       "      <td>2010-06-04 18:31:57</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>152153637639028736</td>\n",
       "      <td>152151847614943233</td>\n",
       "      <td>1325111228000.0</td>\n",
       "      <td>2011-12-28 22:27:08</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TheOnion So true :)</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>151809315026636800</td>\n",
       "      <td>151809315026636800</td>\n",
       "      <td>1325029135000.0</td>\n",
       "      <td>2011-12-27 23:38:55</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you ever wanted to know the *real* truth ab...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>151338939389706242</td>\n",
       "      <td>151338939389706242</td>\n",
       "      <td>1324916990000.0</td>\n",
       "      <td>2011-12-26 16:29:50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>151337237429239808</td>\n",
       "      <td>151337237429239808</td>\n",
       "      <td>1324916584000.0</td>\n",
       "      <td>2011-12-26 16:23:04</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was Xmas, so we brought presents for the ki...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  id     conversation_id       created_at  \\\n",
       "0         0.0         15434727182         15434727182  1275676317000.0   \n",
       "0         0.0  152153637639028736  152151847614943233  1325111228000.0   \n",
       "1         1.0  151809315026636800  151809315026636800  1325029135000.0   \n",
       "2         2.0  151338939389706242  151338939389706242  1324916990000.0   \n",
       "3         3.0  151337237429239808  151337237429239808  1324916584000.0   \n",
       "\n",
       "                  date  timezone  place  \\\n",
       "0  2010-06-04 18:31:57         0    NaN   \n",
       "0  2011-12-28 22:27:08         0    NaN   \n",
       "1  2011-12-27 23:38:55         0    NaN   \n",
       "2  2011-12-26 16:29:50         0    NaN   \n",
       "3  2011-12-26 16:23:04         0    NaN   \n",
       "\n",
       "                                               tweet language hashtags  ...  \\\n",
       "0  Please ignore prior tweets, as that was someon...       en       []  ...   \n",
       "0                               @TheOnion So true :)       en       []  ...   \n",
       "1  If you ever wanted to know the *real* truth ab...       en       []  ...   \n",
       "2  Walked around a neighborhood recently rebuilt ...       en       []  ...   \n",
       "3  It was Xmas, so we brought presents for the ki...       en       []  ...   \n",
       "\n",
       "  reply_to  retweet_date  translate trans_src trans_dest  time  mentions  \\\n",
       "0       []           NaN        NaN       NaN        NaN   NaN       NaN   \n",
       "0       []           NaN        NaN       NaN        NaN   NaN       NaN   \n",
       "1       []           NaN        NaN       NaN        NaN   NaN       NaN   \n",
       "2       []           NaN        NaN       NaN        NaN   NaN       NaN   \n",
       "3       []           NaN        NaN       NaN        NaN   NaN       NaN   \n",
       "\n",
       "  replies_count retweets_count likes_count  \n",
       "0           NaN            NaN         NaN  \n",
       "0           NaN            NaN         NaN  \n",
       "1           NaN            NaN         NaN  \n",
       "2           NaN            NaN         NaN  \n",
       "3           NaN            NaN         NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c8841",
   "metadata": {},
   "source": [
    "## 2. Remove columns that will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e524e",
   "metadata": {},
   "source": [
    "We will be keeping date, timezone, **tweet**, hashtags, mentions, replies_count, retweets_count, likes_count. Only **tweet** variable is for nlp but others might be used for exploratory analysis. Missing values are replaced with zero and date will be separated into year, month, time column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c624723",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data_col = concatenated_df[['date', 'timezone', 'hashtags', 'mentions', 'replies_count', 'retweets_count', 'likes_count', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b68dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 34878 entries, 0 to 1027\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   date            34878 non-null  object \n",
      " 1   timezone        34878 non-null  int64  \n",
      " 2   hashtags        34878 non-null  object \n",
      " 3   mentions        4143 non-null   object \n",
      " 4   replies_count   4143 non-null   float64\n",
      " 5   retweets_count  4143 non-null   float64\n",
      " 6   likes_count     4143 non-null   float64\n",
      " 7   tweet           34878 non-null  object \n",
      "dtypes: float64(3), int64(1), object(4)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "the_data_col.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eceb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the_data_col['date'] = pd.to_datetime(the_data_col['date'])\n",
    "#the_data_col['date'] = the_data_col['date'].dt.strftime('%Y/%d/%m')\n",
    "#the_data_col['time'] = the_data_col['date'].dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566b711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data = the_data_col.fillna(0).replace('[]',0)[['date', 'timezone', 'hashtags', 'mentions', 'replies_count', 'retweets_count', 'likes_count', 'tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d644369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010/04/06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011/28/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@TheOnion So true :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011/27/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If you ever wanted to know the *real* truth ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011/26/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011/26/12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>It was Xmas, so we brought presents for the ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>2022/03/01</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25611.0</td>\n",
       "      <td>51383.0</td>\n",
       "      <td>473530.0</td>\n",
       "      <td>https://t.co/LA9hPzVlGx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>2022/02/01</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>26951.0</td>\n",
       "      <td>320201.0</td>\n",
       "      <td>Letâ€™s make the roaring 20â€™s happen!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>2022/02/01</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5630.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>66405.0</td>\n",
       "      <td>Great work by Tesla team worldwide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>45704.0</td>\n",
       "      <td>@BLKMDL3 @Tesla ðŸ”¥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>2022/01/01</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>@MiFSDBetaTester @WholeMarsBlog ðŸ¤£</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34878 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  timezone hashtags mentions  replies_count  retweets_count  \\\n",
       "0     2010/04/06         0        0        0            0.0             0.0   \n",
       "0     2011/28/12         0        0        0            0.0             0.0   \n",
       "1     2011/27/12         0        0        0            0.0             0.0   \n",
       "2     2011/26/12         0        0        0            0.0             0.0   \n",
       "3     2011/26/12         0        0        0            0.0             0.0   \n",
       "...          ...       ...      ...      ...            ...             ...   \n",
       "1023  2022/03/01       400        0        0        25611.0         51383.0   \n",
       "1024  2022/02/01       400        0        0        22500.0         26951.0   \n",
       "1025  2022/02/01       400        0        0         5630.0          4459.0   \n",
       "1026  2022/01/01       400        0        0         1074.0           472.0   \n",
       "1027  2022/01/01       400        0        0          327.0           151.0   \n",
       "\n",
       "      likes_count                                              tweet  \n",
       "0             0.0  Please ignore prior tweets, as that was someon...  \n",
       "0             0.0                               @TheOnion So true :)  \n",
       "1             0.0  If you ever wanted to know the *real* truth ab...  \n",
       "2             0.0  Walked around a neighborhood recently rebuilt ...  \n",
       "3             0.0  It was Xmas, so we brought presents for the ki...  \n",
       "...           ...                                                ...  \n",
       "1023     473530.0                            https://t.co/LA9hPzVlGx  \n",
       "1024     320201.0                Letâ€™s make the roaring 20â€™s happen!  \n",
       "1025      66405.0                Great work by Tesla team worldwide!  \n",
       "1026      45704.0                                  @BLKMDL3 @Tesla ðŸ”¥  \n",
       "1027       4127.0                  @MiFSDBetaTester @WholeMarsBlog ðŸ¤£  \n",
       "\n",
       "[34878 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d6f96",
   "metadata": {},
   "source": [
    "## 3. Cleaning the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d97d29",
   "metadata": {},
   "source": [
    "**a) We have to keep the hashtags and the mentions alive, so they will be extracted in separate columns and then removed from the tweet column + as before, we have to fill in the missing values with zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35418c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ededfa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving mentions and hashtags to a separate columns\n",
    "the_data[\"hashtags_own\"] = the_data.tweet.str.findall(r'#.*?(?=\\s|$)')\n",
    "the_data[\"mentions_own\"] = the_data.tweet.str.findall(r'@.*?(?=\\s|$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70aad20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PH\\AppData\\Local\\Temp/ipykernel_24776/1645225293.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  the_data['tweet'] = the_data['tweet'].str.replace('[!@#$]','')\n"
     ]
    }
   ],
   "source": [
    "#removing hashtag and mentions sign from the tweet text -> removes only the first one? \n",
    "the_data['tweet'] = the_data['tweet'].str.replace('[!@#$]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba253865",
   "metadata": {},
   "source": [
    "**b) Next, we focus on emojis.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f924925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError: \n",
    "    import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see the progress, install tqdm\n",
    "#!pip install tqdm\n",
    "#from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cf71556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \" \".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86805197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#type(test_df)\n",
    "#ISSUE - object is a series\n",
    "#the_data = the_data.pd.to_frame()\n",
    "#the_data_df = the_data.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b9c804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24776/4206019598.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet_cleaned\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthe_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconvert_emojis_to_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8740\u001b[0m         )\n\u001b[1;32m-> 8741\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24776/4206019598.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet_cleaned\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthe_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconvert_emojis_to_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24776/1667616596.py\u001b[0m in \u001b[0;36mconvert_emojis_to_word\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_emojis_to_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0memot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEmoji_Dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'('\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0memot\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m')'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmoji_Dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0memot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "the_data[\"tweet_cleaned\"] = the_data.apply(lambda x: convert_emojis_to_word(x[\"tweet\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614916a0",
   "metadata": {},
   "source": [
    "**c) To lower, split, stop-words using the pre_process_function together with clean_txt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "059fa93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "global dictionary\n",
    "dictionary = nltk.corpus.words.words(\"en\")\n",
    "dictionary = [word.lower() for word in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "03cbcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt_in):\n",
    "    import re\n",
    "    clean_str = re.sub(\"[^A-Za-z]+\", \" \", txt_in).strip().lower()\n",
    "    return clean_str\n",
    "\n",
    "def pre_process_text(tmp_f):\n",
    "    tmp_f = clean_txt(tmp_f)\n",
    "    tmp_f = [word_t.lower() for word_t in tmp_f.split(\n",
    "        ) if word_t in dictionary]\n",
    "    tmp_f = ' '.join(tmp_f)\n",
    "    return tmp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c7fbbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22632/3646218995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet_cleaned\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthe_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8739\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8740\u001b[0m         )\n\u001b[1;32m-> 8741\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8742\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8743\u001b[0m     def applymap(\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ph\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22632/3646218995.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet_cleaned\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthe_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22632/2380451585.py\u001b[0m in \u001b[0;36mpre_process_text\u001b[1;34m(tmp_f)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtmp_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_txt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     tmp_f = [word_t.lower() for word_t in tmp_f.split(\n\u001b[0m\u001b[0;32m      4\u001b[0m         ) if word_t in dictionary]\n\u001b[0;32m      5\u001b[0m     \u001b[0mtmp_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22632/2380451585.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtmp_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_txt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     tmp_f = [word_t.lower() for word_t in tmp_f.split(\n\u001b[0m\u001b[0;32m      4\u001b[0m         ) if word_t in dictionary]\n\u001b[0;32m      5\u001b[0m     \u001b[0mtmp_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "the_data[\"tweet_cleaned\"] = the_data.apply(lambda x: pre_process_text(x[\"tweet_cleaned\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words\n",
    "def my_stop_words(var_in):\n",
    "    from nltk.corpus import stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    tmp = [word for word in var_in.split() if word not in sw]\n",
    "    tmp = ' '.join(tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6319554",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data[\"tweet_cleaned\"] = the_data.apply(lambda x: my_stop_words(x[\"tweet_cleaned\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc297b",
   "metadata": {},
   "source": [
    "**d) Save the cleaned data as a pickle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(path_in, file_name, var_in):\n",
    "    import pickle\n",
    "    pickle.dump(var_in, open(path_in + file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle(the_data_out, \"data_cleaned.pkl\", the_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
